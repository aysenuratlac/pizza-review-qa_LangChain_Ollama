

===== /Users/selimaksoy/Documents/ollama_langchain_case1/vector.py =====

from langchain_ollama import OllamaEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document
import os
import pandas as pd

df = pd.read_csv("realistic_restaurant_reviews.csv")
embeddings = OllamaEmbeddings(model="mxbai-embed-large")

db_location = "./chrome_langchain_db"
add_documents = not os.path.exists(db_location)

if add_documents:
    documents = []
    ids = []
    
    for i, row in df.iterrows():
        document = Document(
            page_content=row["Title"] + " " + row["Review"],
            metadata={"rating": row["Rating"], "date": row["Date"]},
            id=str(i)
        )
        ids.append(str(i))
        documents.append(document)
        
vector_store = Chroma(
    collection_name="restaurant_reviews",
    persist_directory=db_location,
    embedding_function=embeddings
)

if add_documents:
    vector_store.add_documents(documents=documents, ids=ids)
    
retriever = vector_store.as_retriever(
    search_kwargs={"k": 5}
)

===== /Users/selimaksoy/Documents/ollama_langchain_case1/requirements.txt =====

langchain
langchain-ollama
langchain-chroma
pandas

===== /Users/selimaksoy/Documents/ollama_langchain_case1/commands_notes.txt =====

pip install -r requirements.txt

python3 -m venv venv  

python3 ./main.py 

source ./venv/bin/activate 



===== /Users/selimaksoy/Documents/ollama_langchain_case1/project_to_text.py =====

import os

# KAYNAK klasör yolu (proje klasörünü buraya yaz)
SOURCE_FOLDER = "/Users/selimaksoy/Documents/ollama_langchain_case1"

# ÇIKTI dosyası
OUTPUT_FILE = "project.txt"

# Hangi dosya uzantılarını ekleyeceğiz
INCLUDE_EXTENSIONS = {".py", ".js", ".ts", ".html", ".css", ".json", ".txt", ".md", ".java", ".c", ".cpp", ".cs"}

# Dahil edilmeyecek klasörler
EXCLUDE_FOLDERS = {"venv", ".venv", "__pycache__", "node_modules"}

def project_to_text(source_folder, output_file):
    with open(output_file, "w", encoding="utf-8") as outfile:
        for root, dirs, files in os.walk(source_folder):
            # Gereksiz klasörleri çıkart
            dirs[:] = [d for d in dirs if d not in EXCLUDE_FOLDERS]

            for file in files:
                ext = os.path.splitext(file)[1].lower()
                if ext in INCLUDE_EXTENSIONS:
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, "r", encoding="utf-8", errors="ignore") as infile:
                            outfile.write(f"\n\n===== {file_path} =====\n\n")
                            outfile.write(infile.read())
                    except Exception as e:
                        print(f"Hata: {file_path} okunamadı. ({e})")

    print(f"Tüm kodlar '{output_file}' dosyasına aktarıldı.")

# Çalıştır
project_to_text(SOURCE_FOLDER, OUTPUT_FILE)


===== /Users/selimaksoy/Documents/ollama_langchain_case1/project.txt =====



===== /Users/selimaksoy/Documents/ollama_langchain_case1/main.py =====

from langchain_ollama.llms import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate
from vector import retriever

model = OllamaLLM(model="llama3.2")

template = """
You are an exeprt in answering questions about a pizza restaurant

Here are some relevant reviews: {reviews}

Here is the question to answer: {question}
"""
prompt = ChatPromptTemplate.from_template(template)
chain = prompt | model

while True:
    print("\n\n-------------------------------")
    question = input("Ask your question (q to quit): ")
    print("\n\n")
    if question == "q":
        break
    
    reviews = retriever.invoke(question)
    result = chain.invoke({"reviews": reviews, "question": question})
    print(result)